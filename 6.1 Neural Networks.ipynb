{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoSDyYpdh-s"
      },
      "source": [
        "Assignment 7: Neural Networks using Keras and Tensorflow Please see the associated document for questions\n",
        "\n",
        "If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEDLrDNUVZ-m",
        "outputId": "6e9ed52e-3c86-4806-9ac2-3ca6f42196f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras import utils as np_utils\n",
        "import tensorflow\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Hyper-parameters data-loading and formatting\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 40\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "#Pre processing\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(lbl_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(lbl_test, num_classes)\n",
        "\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation = 'relu'))\n",
        "model.add(Dense(300, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
        "        metrics=['accuracy'],)\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EXPM52_HPdOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234cbae3-5754-41eb-91b9-9dac2cdc2b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 14s 11ms/step - loss: 0.3998 - accuracy: 0.8906 - val_loss: 0.2186 - val_accuracy: 0.9376\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1880 - accuracy: 0.9457 - val_loss: 0.1603 - val_accuracy: 0.9514\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1373 - accuracy: 0.9602 - val_loss: 0.1251 - val_accuracy: 0.9646\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.1078 - accuracy: 0.9687 - val_loss: 0.1071 - val_accuracy: 0.9678\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9747 - val_loss: 0.0902 - val_accuracy: 0.9735\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9793 - val_loss: 0.0866 - val_accuracy: 0.9748\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9823 - val_loss: 0.0774 - val_accuracy: 0.9758\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0536 - accuracy: 0.9851 - val_loss: 0.0768 - val_accuracy: 0.9760\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.0740 - val_accuracy: 0.9777\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9889 - val_loss: 0.0705 - val_accuracy: 0.9781\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9909 - val_loss: 0.0687 - val_accuracy: 0.9784\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0299 - accuracy: 0.9924 - val_loss: 0.0670 - val_accuracy: 0.9797\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0642 - val_accuracy: 0.9792\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0631 - val_accuracy: 0.9797\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 0.0611 - val_accuracy: 0.9812\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0680 - val_accuracy: 0.9793\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0617 - val_accuracy: 0.9812\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.0602 - val_accuracy: 0.9813\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9989 - val_loss: 0.0661 - val_accuracy: 0.9799\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.0615 - val_accuracy: 0.9816\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0627 - val_accuracy: 0.9809\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0633 - val_accuracy: 0.9804\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0637 - val_accuracy: 0.9810\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0642 - val_accuracy: 0.9808\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0647 - val_accuracy: 0.9811\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9818\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0637 - val_accuracy: 0.9812\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0635 - val_accuracy: 0.9814\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9809\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0651 - val_accuracy: 0.9814\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9809\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9810\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9815\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9815\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9818\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9819\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9817\n",
            "Test loss: 0.0675123929977417, Test accuracy 0.9817000031471252\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ZYZ-WmdhwH"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras import utils as np_utils\n",
        "import tensorflow\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJRCoRmew8Zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349bb699-6a57-44aa-bad4-688dcc741fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Hyper-parameters data-loading and formatting\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Ktucinc9sl",
        "outputId": "f948e14b-5f84-4dc3-f7eb-35e299d1b42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47040000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3g1RrZ0wpI"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UswCCQLS0s1I"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(lbl_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(lbl_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.1: Explain the data pre-processing highlighted in the notebook**\n",
        "\n",
        "Above the data is converted from an 8-bit integer (*able to take values between 0 and 255*) to an float to make sure it can handle fraction values as the data in the next step is normalized to be a number between 0 and 1. Normalizing the data is done to make the training of the model easier to speed up the process and achieve better performance as the learning algorithm performes better on small values.\n",
        "\n",
        "The last preprocessing step that is done transformes the data from an array to the encoded format, here one-hot encoded where the data is represented by a binary matrix."
      ],
      "metadata": {
        "id": "aegmERLBcyFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7Aer42gk1W9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc5180e-b4ea-405b-d926-1397feea9282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.4754 - accuracy: 0.8622 - val_loss: 0.2699 - val_accuracy: 0.9224\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2330 - accuracy: 0.9321 - val_loss: 0.1904 - val_accuracy: 0.9460\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1789 - accuracy: 0.9482 - val_loss: 0.1808 - val_accuracy: 0.9449\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1474 - accuracy: 0.9576 - val_loss: 0.1468 - val_accuracy: 0.9555\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1261 - accuracy: 0.9634 - val_loss: 0.1343 - val_accuracy: 0.9598\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1094 - accuracy: 0.9681 - val_loss: 0.1099 - val_accuracy: 0.9683\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0972 - accuracy: 0.9724 - val_loss: 0.1390 - val_accuracy: 0.9557\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9745 - val_loss: 0.0993 - val_accuracy: 0.9693\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.1017 - val_accuracy: 0.9680\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0718 - accuracy: 0.9792 - val_loss: 0.0964 - val_accuracy: 0.9704\n",
            "Test loss: 0.09636350721120834, Test accuracy 0.9703999757766724\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
        "        metrics=['accuracy'],)\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's address each of the questions one by one using the provided code:\n",
        "\n",
        "1. Network Structure:\n",
        "How many layers does the network in the notebook have?\n",
        "The model has the following layers:\n",
        "\n",
        "- Flatten()\n",
        "- Dense(64, activation='relu')\n",
        "- Dense(64, activation='relu')\n",
        "- Dense(num_classes, activation='softmax')\n",
        "So, it has a total of 4 layers.\n",
        "\n",
        "How many neurons does each layer have?\n",
        "\n",
        "The Flatten() layer doesn't have \"neurons\" in the traditional sense. It reshapes the input without any trainable parameters.\n",
        "\n",
        "The next two Dense layers each have 64 neurons.\n",
        "\n",
        "The final Dense layer has num_classes neurons, which depends on the value of num_classes which is equal to 10.\n",
        "\n",
        "\n",
        "What activation functions and why are these appropriate for this application?\n",
        "\n",
        "The first two Dense layers use the ReLU (Rectified Linear Unit) activation function. ReLU is widely used in deep learning because it helps with the vanishing gradient problem and is computationally efficient. It introduces non-linearity without being bound by a fixed output range.\n",
        "The final Dense layer uses the Softmax activation function, which outputs a probability distribution over multiple classes. It's suitable for multi-class classification tasks.\n",
        "\n",
        "\n",
        "Why do the input and output layers have the dimensions they have?\n",
        "The Flatten() layer is typically used to convert multi-dimensional input (like a 2D image) into a 1D array so that it can be fed into fully connected layers.\n",
        "\n",
        "The final layer has num_classes neurons because it corresponds to the number of classes in the classification task. Each neuron will output the probability of the input belonging to its respective class.\n",
        "\n",
        "What is the total number of parameters for the network?\n",
        "\n",
        "To determine this, you'd typically call model.summary(), which would print out a summary of the model, including the number of parameters in each layer and the total parameters. Without knowing the input shape to the Flatten layer or the value of num_classes, we can't provide an exact number here.\n",
        "\n",
        "\n",
        "2. Loss Function and Training:\n",
        "What loss function is used to train the network?\n",
        "The loss function used is categorical_crossentropy.\n",
        "\n",
        "What is the functional form (a mathematical expression) of the loss function?\n",
        "For true label y and predicted label y-hat\n",
        "![image.png](data:image/png;base64,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)​\n",
        "  over\n",
        "�\n",
        "C classes:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ",\n",
        "�\n",
        "^\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "�\n",
        "=\n",
        "1\n",
        "�\n",
        "�\n",
        "�\n",
        "log\n",
        "⁡\n",
        "(\n",
        "�\n",
        "^\n",
        "�\n",
        ")\n",
        "L(y,\n",
        "y\n",
        "^\n",
        "​\n",
        " )=−∑\n",
        "i=1\n",
        "C\n",
        "​\n",
        " y\n",
        "i\n",
        "​\n",
        " log(\n",
        "y\n",
        "^\n",
        "​\n",
        "  \n",
        "i\n",
        "​\n",
        " )\n",
        "\n",
        "This loss is suitable when the target labels are one-hot encoded, which they are in this case.\n",
        "\n",
        "How should we interpret it?\n",
        "The categorical cross-entropy loss measures the dissimilarity between the true label distribution and the predicted probabilities. A lower loss indicates better performance with predictions closer to the true labels.\n",
        "\n",
        "Why is it appropriate for the problem at hand?\n",
        "Categorical cross-entropy is suitable for multi-class classification problems. Given that the final layer uses a softmax activation (indicating multi-class classification), this loss function is appropriate.\n",
        "\n",
        "In summary, this code defines a neural network with two hidden layers for multi-class classification and uses categorical cross-entropy as its loss function."
      ],
      "metadata": {
        "id": "66NBiJKvf2CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract training and validation accuracy\n",
        "train_acc = fit_info.history['accuracy']\n",
        "val_acc = fit_info.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "_9iAtBKsLJBv",
        "outputId": "08b753b8-9fe4-423b-cbbc-91b534aae186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-adf71c110291>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extract training and validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fit_info' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define model ##\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(500, activation = 'relu'))\n",
        "model2.add(Dense(300, activation = 'relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
        "        metrics=['accuracy'],)\n",
        "\n",
        "fit_info = model2.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=40,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do8hLZewNsvt",
        "outputId": "3bfbde32-2be3-4ce7-d4c8-8c5a7eba203e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3973 - accuracy: 0.8896 - val_loss: 0.2246 - val_accuracy: 0.9313\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1896 - accuracy: 0.9449 - val_loss: 0.1516 - val_accuracy: 0.9555\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1380 - accuracy: 0.9601 - val_loss: 0.1323 - val_accuracy: 0.9610\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1098 - accuracy: 0.9686 - val_loss: 0.1118 - val_accuracy: 0.9673\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.0965 - val_accuracy: 0.9715\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9791 - val_loss: 0.0863 - val_accuracy: 0.9729\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0637 - accuracy: 0.9821 - val_loss: 0.0802 - val_accuracy: 0.9753\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0551 - accuracy: 0.9844 - val_loss: 0.0748 - val_accuracy: 0.9765\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.9865 - val_loss: 0.0741 - val_accuracy: 0.9770\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.0839 - val_accuracy: 0.9731\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.0688 - val_accuracy: 0.9779\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0309 - accuracy: 0.9921 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0669 - val_accuracy: 0.9784\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9946 - val_loss: 0.0621 - val_accuracy: 0.9812\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9955 - val_loss: 0.0679 - val_accuracy: 0.9782\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0178 - accuracy: 0.9966 - val_loss: 0.0637 - val_accuracy: 0.9810\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.0601 - val_accuracy: 0.9812\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.0626 - val_accuracy: 0.9806\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.0625 - val_accuracy: 0.9813\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0612 - val_accuracy: 0.9813\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.0603 - val_accuracy: 0.9822\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0625 - val_accuracy: 0.9819\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0611 - val_accuracy: 0.9816\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0628 - val_accuracy: 0.9811\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.0617 - val_accuracy: 0.9817\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0628 - val_accuracy: 0.9812\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0631 - val_accuracy: 0.9809\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0628 - val_accuracy: 0.9816\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0633 - val_accuracy: 0.9815\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0642 - val_accuracy: 0.9811\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9816\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9819\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9821\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9813\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9816\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9812\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9821\n",
            "Test loss: 0.09636350721120834, Test accuracy 0.9703999757766724\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract training and validation accuracy\n",
        "train_acc = fit_info.history['accuracy']\n",
        "val_acc = fit_info.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(epochs, train_acc, 'o', label='Training accuracy', markersize=5)\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "max_val_accuracy = max(val_acc)\n",
        "print(f\"Maximum Validation Accuracy: {max_val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "3Cg-k5rORPVt",
        "outputId": "0a0b2c60-fe74-4f13-90a9-6a234788f400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Validation Accuracy: 0.9822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hinton achived an accuracy of 0.9847 while we only achive an accuracy of 0.9828. We are close but not as accurate as him. This can depend on."
      ],
      "metadata": {
        "id": "3zNucat-bWmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 cont."
      ],
      "metadata": {
        "id": "qs7UBcu3UsP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "import numpy as np\n",
        "\n",
        "# Regularization factors to try\n",
        "regularization_factors = [0.000001, 0.00001, 0.0001, 0.001, 0.01]\n",
        "\n",
        "\n",
        "val_acc_mean_tot = []\n",
        "std_acc_tot = []\n",
        "\n",
        "for reg_factor in regularization_factors:\n",
        "  val_acc = []\n",
        "  std = []\n",
        "  for i in range(3):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Add L2 regularization (weight decay) to the hidden layers\n",
        "    model.add(Dense(500, activation='relu', kernel_regularizer=l2(reg_factor)))\n",
        "    model.add(Dense(300, activation='relu', kernel_regularizer=l2(reg_factor)))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.1),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(f\"Training model with regularization factor: {reg_factor}\")\n",
        "    fit_info = model.fit(x_train, y_train,\n",
        "               batch_size=batch_size,\n",
        "               epochs=40,\n",
        "               verbose=1,\n",
        "               validation_data=(x_test, y_test))\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Regularization Factor {reg_factor} - Test loss: {score[0]}, Test accuracy: {score[1]}\\n\")\n",
        "    model.summary()\n",
        "\n",
        "    val_acc.append((fit_info.history['val_accuracy']))\n",
        "\n",
        "\n",
        "  val_acc_mean_tot.append(np.mean(val_acc))\n",
        "  std_acc_tot.append(np.std(val_acc))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mXDEtXWV1sp",
        "outputId": "a9993203-e350-4f86-a597-e6aedb7cf82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with regularization factor: 1e-06\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.4022 - accuracy: 0.8897 - val_loss: 0.2312 - val_accuracy: 0.9297\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1873 - accuracy: 0.9465 - val_loss: 0.1530 - val_accuracy: 0.9537\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1380 - accuracy: 0.9601 - val_loss: 0.1382 - val_accuracy: 0.9581\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1087 - accuracy: 0.9693 - val_loss: 0.1066 - val_accuracy: 0.9667\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0895 - accuracy: 0.9753 - val_loss: 0.0997 - val_accuracy: 0.9685\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9792 - val_loss: 0.0837 - val_accuracy: 0.9738\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9826 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0549 - accuracy: 0.9849 - val_loss: 0.0832 - val_accuracy: 0.9730\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0474 - accuracy: 0.9872 - val_loss: 0.0779 - val_accuracy: 0.9744\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9894 - val_loss: 0.0672 - val_accuracy: 0.9785\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0708 - val_accuracy: 0.9775\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0664 - val_accuracy: 0.9795\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0273 - accuracy: 0.9934 - val_loss: 0.0667 - val_accuracy: 0.9794\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0238 - accuracy: 0.9946 - val_loss: 0.0651 - val_accuracy: 0.9804\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0628 - val_accuracy: 0.9793\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 0.0620 - val_accuracy: 0.9812\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.0618 - val_accuracy: 0.9800\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9984 - val_loss: 0.0633 - val_accuracy: 0.9815\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.0618 - val_accuracy: 0.9808\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.0629 - val_accuracy: 0.9798\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9994 - val_loss: 0.0631 - val_accuracy: 0.9806\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0633 - val_accuracy: 0.9807\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.0628 - val_accuracy: 0.9805\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0639 - val_accuracy: 0.9804\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0641 - val_accuracy: 0.9805\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0642 - val_accuracy: 0.9802\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0658 - val_accuracy: 0.9801\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9805\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0661 - val_accuracy: 0.9807\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9810\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9811\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9812\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9811\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9809\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
            "Regularization Factor 1e-06 - Test loss: 0.0670187920331955, Test accuracy: 0.9804999828338623\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 1e-06\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4004 - accuracy: 0.8898 - val_loss: 0.2145 - val_accuracy: 0.9389\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1875 - accuracy: 0.9463 - val_loss: 0.1487 - val_accuracy: 0.9567\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1369 - accuracy: 0.9611 - val_loss: 0.1214 - val_accuracy: 0.9636\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1079 - accuracy: 0.9690 - val_loss: 0.1014 - val_accuracy: 0.9692\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9751 - val_loss: 0.1101 - val_accuracy: 0.9656\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9793 - val_loss: 0.0810 - val_accuracy: 0.9763\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9823 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0541 - accuracy: 0.9852 - val_loss: 0.0717 - val_accuracy: 0.9777\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0466 - accuracy: 0.9873 - val_loss: 0.0695 - val_accuracy: 0.9794\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0732 - val_accuracy: 0.9777\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 0.0641 - val_accuracy: 0.9808\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 0.0605 - val_accuracy: 0.9819\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0268 - accuracy: 0.9937 - val_loss: 0.0641 - val_accuracy: 0.9810\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0238 - accuracy: 0.9947 - val_loss: 0.0625 - val_accuracy: 0.9804\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.0658 - val_accuracy: 0.9803\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9812\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 0.0605 - val_accuracy: 0.9814\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0613 - val_accuracy: 0.9817\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9984 - val_loss: 0.0606 - val_accuracy: 0.9819\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.0618 - val_accuracy: 0.9815\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.0618 - val_accuracy: 0.9826\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.0646 - val_accuracy: 0.9810\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0615 - val_accuracy: 0.9820\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.0642 - val_accuracy: 0.9812\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0624 - val_accuracy: 0.9824\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0617 - val_accuracy: 0.9820\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0637 - val_accuracy: 0.9812\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.0623 - val_accuracy: 0.9819\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0633 - val_accuracy: 0.9820\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0639 - val_accuracy: 0.9822\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9820\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0633 - val_accuracy: 0.9827\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9826\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9825\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9816\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9823\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9824\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9824\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9820\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9824\n",
            "Regularization Factor 1e-06 - Test loss: 0.066547691822052, Test accuracy: 0.9824000000953674\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 1e-06\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4029 - accuracy: 0.8896 - val_loss: 0.2312 - val_accuracy: 0.9311\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1886 - accuracy: 0.9458 - val_loss: 0.1543 - val_accuracy: 0.9560\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1387 - accuracy: 0.9604 - val_loss: 0.1304 - val_accuracy: 0.9623\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9685 - val_loss: 0.1081 - val_accuracy: 0.9671\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 0.0938 - val_accuracy: 0.9723\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0759 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9723\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9819 - val_loss: 0.0787 - val_accuracy: 0.9753\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9852 - val_loss: 0.0955 - val_accuracy: 0.9706\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.0778 - val_accuracy: 0.9751\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.0707 - val_accuracy: 0.9776\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 0.0712 - val_accuracy: 0.9786\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0311 - accuracy: 0.9924 - val_loss: 0.0671 - val_accuracy: 0.9798\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.0666 - val_accuracy: 0.9801\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.0672 - val_accuracy: 0.9793\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0629 - val_accuracy: 0.9812\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 0.0624 - val_accuracy: 0.9814\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.0633 - val_accuracy: 0.9816\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.0633 - val_accuracy: 0.9817\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0640 - val_accuracy: 0.9815\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.0750 - val_accuracy: 0.9777\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0636 - val_accuracy: 0.9811\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0668 - val_accuracy: 0.9817\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.0640 - val_accuracy: 0.9823\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0647 - val_accuracy: 0.9820\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0685 - val_accuracy: 0.9805\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0651 - val_accuracy: 0.9815\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0649 - val_accuracy: 0.9827\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0668 - val_accuracy: 0.9814\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0662 - val_accuracy: 0.9815\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0666 - val_accuracy: 0.9820\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9820\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0665 - val_accuracy: 0.9823\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9818\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9821\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9820\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9822\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9820\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9818\n",
            "Regularization Factor 1e-06 - Test loss: 0.0690426379442215, Test accuracy: 0.9818000197410583\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 1e-05\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4096 - accuracy: 0.8902 - val_loss: 0.2419 - val_accuracy: 0.9317\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1992 - accuracy: 0.9455 - val_loss: 0.1623 - val_accuracy: 0.9540\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1481 - accuracy: 0.9607 - val_loss: 0.1305 - val_accuracy: 0.9642\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1193 - accuracy: 0.9687 - val_loss: 0.1254 - val_accuracy: 0.9649\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9743 - val_loss: 0.0996 - val_accuracy: 0.9731\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0847 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9740\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0737 - accuracy: 0.9819 - val_loss: 0.0923 - val_accuracy: 0.9757\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9844 - val_loss: 0.0866 - val_accuracy: 0.9758\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9870 - val_loss: 0.0892 - val_accuracy: 0.9757\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0517 - accuracy: 0.9891 - val_loss: 0.0826 - val_accuracy: 0.9780\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0464 - accuracy: 0.9907 - val_loss: 0.1073 - val_accuracy: 0.9686\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0416 - accuracy: 0.9922 - val_loss: 0.0778 - val_accuracy: 0.9791\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9934 - val_loss: 0.0763 - val_accuracy: 0.9787\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.9947 - val_loss: 0.0736 - val_accuracy: 0.9800\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0315 - accuracy: 0.9955 - val_loss: 0.0737 - val_accuracy: 0.9801\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0289 - accuracy: 0.9962 - val_loss: 0.0769 - val_accuracy: 0.9790\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0269 - accuracy: 0.9971 - val_loss: 0.0829 - val_accuracy: 0.9772\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0249 - accuracy: 0.9976 - val_loss: 0.0756 - val_accuracy: 0.9794\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9982 - val_loss: 0.0722 - val_accuracy: 0.9815\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9988 - val_loss: 0.0725 - val_accuracy: 0.9818\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.9988 - val_loss: 0.0759 - val_accuracy: 0.9800\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.0742 - val_accuracy: 0.9811\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.9993 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0181 - accuracy: 0.9994 - val_loss: 0.0746 - val_accuracy: 0.9812\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0174 - accuracy: 0.9996 - val_loss: 0.0745 - val_accuracy: 0.9809\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0168 - accuracy: 0.9996 - val_loss: 0.0756 - val_accuracy: 0.9805\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9998 - val_loss: 0.0753 - val_accuracy: 0.9810\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0158 - accuracy: 0.9998 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0750 - val_accuracy: 0.9820\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0150 - accuracy: 0.9999 - val_loss: 0.0761 - val_accuracy: 0.9807\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9999 - val_loss: 0.0764 - val_accuracy: 0.9814\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.0759 - val_accuracy: 0.9813\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9816\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9999 - val_loss: 0.0769 - val_accuracy: 0.9803\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9815\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9814\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9814\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9807\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9812\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9816\n",
            "Regularization Factor 1e-05 - Test loss: 0.07870279252529144, Test accuracy: 0.9815999865531921\n",
            "\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 1e-05\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.4167 - accuracy: 0.8879 - val_loss: 0.2237 - val_accuracy: 0.9403\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1999 - accuracy: 0.9450 - val_loss: 0.1644 - val_accuracy: 0.9568\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9603 - val_loss: 0.1328 - val_accuracy: 0.9644\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1192 - accuracy: 0.9682 - val_loss: 0.1215 - val_accuracy: 0.9645\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9748 - val_loss: 0.0982 - val_accuracy: 0.9733\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0854 - accuracy: 0.9789 - val_loss: 0.0941 - val_accuracy: 0.9750\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9818 - val_loss: 0.0865 - val_accuracy: 0.9755\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0658 - accuracy: 0.9848 - val_loss: 0.0839 - val_accuracy: 0.9780\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0593 - accuracy: 0.9863 - val_loss: 0.0798 - val_accuracy: 0.9785\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9887 - val_loss: 0.0785 - val_accuracy: 0.9783\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.9903 - val_loss: 0.0763 - val_accuracy: 0.9788\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0433 - accuracy: 0.9916 - val_loss: 0.0764 - val_accuracy: 0.9799\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9927 - val_loss: 0.0754 - val_accuracy: 0.9799\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0362 - accuracy: 0.9939 - val_loss: 0.0745 - val_accuracy: 0.9795\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0332 - accuracy: 0.9949 - val_loss: 0.0728 - val_accuracy: 0.9812\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.9959 - val_loss: 0.0727 - val_accuracy: 0.9814\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0281 - accuracy: 0.9968 - val_loss: 0.0729 - val_accuracy: 0.9810\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9972 - val_loss: 0.0744 - val_accuracy: 0.9807\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0244 - accuracy: 0.9977 - val_loss: 0.0791 - val_accuracy: 0.9789\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9984 - val_loss: 0.0739 - val_accuracy: 0.9810\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0218 - accuracy: 0.9986 - val_loss: 0.0728 - val_accuracy: 0.9811\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9990 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.9991 - val_loss: 0.0714 - val_accuracy: 0.9817\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9994 - val_loss: 0.0726 - val_accuracy: 0.9811\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 0.0715 - val_accuracy: 0.9818\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0173 - accuracy: 0.9994 - val_loss: 0.0720 - val_accuracy: 0.9816\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9996 - val_loss: 0.0763 - val_accuracy: 0.9809\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9820\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9998 - val_loss: 0.0731 - val_accuracy: 0.9816\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0757 - val_accuracy: 0.9812\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0151 - accuracy: 0.9999 - val_loss: 0.0733 - val_accuracy: 0.9824\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0740 - val_accuracy: 0.9812\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0147 - accuracy: 0.9998 - val_loss: 0.0752 - val_accuracy: 0.9814\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9999 - val_loss: 0.0743 - val_accuracy: 0.9825\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9821\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9999 - val_loss: 0.0741 - val_accuracy: 0.9825\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9822\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9821\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9822\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9819\n",
            "Regularization Factor 1e-05 - Test loss: 0.07575170695781708, Test accuracy: 0.9818999767303467\n",
            "\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 1e-05\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4071 - accuracy: 0.8905 - val_loss: 0.2534 - val_accuracy: 0.9308\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1996 - accuracy: 0.9454 - val_loss: 0.1680 - val_accuracy: 0.9534\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1488 - accuracy: 0.9602 - val_loss: 0.1387 - val_accuracy: 0.9618\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1192 - accuracy: 0.9680 - val_loss: 0.1182 - val_accuracy: 0.9659\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9748 - val_loss: 0.1025 - val_accuracy: 0.9713\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9794 - val_loss: 0.0939 - val_accuracy: 0.9740\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.9821 - val_loss: 0.0919 - val_accuracy: 0.9737\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9845 - val_loss: 0.0911 - val_accuracy: 0.9745\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9870 - val_loss: 0.0872 - val_accuracy: 0.9753\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9891 - val_loss: 0.0915 - val_accuracy: 0.9732\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0456 - accuracy: 0.9905 - val_loss: 0.0788 - val_accuracy: 0.9772\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0415 - accuracy: 0.9920 - val_loss: 0.0832 - val_accuracy: 0.9774\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0378 - accuracy: 0.9933 - val_loss: 0.0770 - val_accuracy: 0.9790\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0340 - accuracy: 0.9947 - val_loss: 0.0734 - val_accuracy: 0.9799\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0311 - accuracy: 0.9959 - val_loss: 0.0758 - val_accuracy: 0.9796\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0285 - accuracy: 0.9967 - val_loss: 0.0732 - val_accuracy: 0.9802\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9971 - val_loss: 0.0756 - val_accuracy: 0.9796\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9979 - val_loss: 0.0726 - val_accuracy: 0.9800\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0231 - accuracy: 0.9981 - val_loss: 0.0748 - val_accuracy: 0.9797\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0216 - accuracy: 0.9987 - val_loss: 0.0745 - val_accuracy: 0.9800\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9989 - val_loss: 0.0737 - val_accuracy: 0.9801\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.9992 - val_loss: 0.0764 - val_accuracy: 0.9802\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.9994 - val_loss: 0.0747 - val_accuracy: 0.9807\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0178 - accuracy: 0.9995 - val_loss: 0.0741 - val_accuracy: 0.9803\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9996 - val_loss: 0.0745 - val_accuracy: 0.9808\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9997 - val_loss: 0.0744 - val_accuracy: 0.9807\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0163 - accuracy: 0.9997 - val_loss: 0.0761 - val_accuracy: 0.9808\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0158 - accuracy: 0.9998 - val_loss: 0.0751 - val_accuracy: 0.9808\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9998 - val_loss: 0.0765 - val_accuracy: 0.9809\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0151 - accuracy: 0.9999 - val_loss: 0.0782 - val_accuracy: 0.9798\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9999 - val_loss: 0.0776 - val_accuracy: 0.9806\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.0766 - val_accuracy: 0.9814\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9999 - val_loss: 0.0776 - val_accuracy: 0.9809\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9999 - val_loss: 0.0774 - val_accuracy: 0.9810\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9999 - val_loss: 0.0785 - val_accuracy: 0.9806\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9811\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9814\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9812\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9816\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9814\n",
            "Regularization Factor 1e-05 - Test loss: 0.07815451920032501, Test accuracy: 0.9814000129699707\n",
            "\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.0001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.5007 - accuracy: 0.8899 - val_loss: 0.3178 - val_accuracy: 0.9365\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2878 - accuracy: 0.9469 - val_loss: 0.2577 - val_accuracy: 0.9550\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2363 - accuracy: 0.9605 - val_loss: 0.2233 - val_accuracy: 0.9622\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2067 - accuracy: 0.9690 - val_loss: 0.2123 - val_accuracy: 0.9660\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9747 - val_loss: 0.1899 - val_accuracy: 0.9716\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1710 - accuracy: 0.9791 - val_loss: 0.1798 - val_accuracy: 0.9741\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1594 - accuracy: 0.9822 - val_loss: 0.1805 - val_accuracy: 0.9732\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1493 - accuracy: 0.9847 - val_loss: 0.1704 - val_accuracy: 0.9759\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1420 - accuracy: 0.9865 - val_loss: 0.1652 - val_accuracy: 0.9779\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1349 - accuracy: 0.9887 - val_loss: 0.1618 - val_accuracy: 0.9788\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1288 - accuracy: 0.9905 - val_loss: 0.1568 - val_accuracy: 0.9788\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1228 - accuracy: 0.9919 - val_loss: 0.1536 - val_accuracy: 0.9799\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1187 - accuracy: 0.9930 - val_loss: 0.1520 - val_accuracy: 0.9801\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1148 - accuracy: 0.9937 - val_loss: 0.1487 - val_accuracy: 0.9790\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1106 - accuracy: 0.9949 - val_loss: 0.1540 - val_accuracy: 0.9795\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9958 - val_loss: 0.1525 - val_accuracy: 0.9801\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1039 - accuracy: 0.9968 - val_loss: 0.1454 - val_accuracy: 0.9808\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1012 - accuracy: 0.9970 - val_loss: 0.1439 - val_accuracy: 0.9811\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0980 - accuracy: 0.9980 - val_loss: 0.1447 - val_accuracy: 0.9795\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0961 - accuracy: 0.9981 - val_loss: 0.1398 - val_accuracy: 0.9818\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0935 - accuracy: 0.9984 - val_loss: 0.1390 - val_accuracy: 0.9807\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0915 - accuracy: 0.9985 - val_loss: 0.1364 - val_accuracy: 0.9813\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0895 - accuracy: 0.9990 - val_loss: 0.1393 - val_accuracy: 0.9802\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9993 - val_loss: 0.1370 - val_accuracy: 0.9813\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0860 - accuracy: 0.9992 - val_loss: 0.1387 - val_accuracy: 0.9796\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0844 - accuracy: 0.9993 - val_loss: 0.1328 - val_accuracy: 0.9819\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0826 - accuracy: 0.9996 - val_loss: 0.1339 - val_accuracy: 0.9806\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0813 - accuracy: 0.9995 - val_loss: 0.1308 - val_accuracy: 0.9813\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9996 - val_loss: 0.1293 - val_accuracy: 0.9812\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0784 - accuracy: 0.9997 - val_loss: 0.1312 - val_accuracy: 0.9805\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0771 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9817\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9998 - val_loss: 0.1260 - val_accuracy: 0.9818\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9998 - val_loss: 0.1259 - val_accuracy: 0.9818\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9999 - val_loss: 0.1259 - val_accuracy: 0.9809\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9999 - val_loss: 0.1238 - val_accuracy: 0.9817\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9999 - val_loss: 0.1243 - val_accuracy: 0.9815\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9821\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9999 - val_loss: 0.1203 - val_accuracy: 0.9816\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9999 - val_loss: 0.1198 - val_accuracy: 0.9816\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9999 - val_loss: 0.1186 - val_accuracy: 0.9823\n",
            "Regularization Factor 0.0001 - Test loss: 0.11859610676765442, Test accuracy: 0.9822999835014343\n",
            "\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.0001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.5077 - accuracy: 0.8867 - val_loss: 0.3098 - val_accuracy: 0.9385\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2922 - accuracy: 0.9445 - val_loss: 0.2610 - val_accuracy: 0.9524\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2417 - accuracy: 0.9593 - val_loss: 0.2256 - val_accuracy: 0.9631\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9675 - val_loss: 0.2072 - val_accuracy: 0.9657\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1912 - accuracy: 0.9731 - val_loss: 0.1927 - val_accuracy: 0.9689\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1762 - accuracy: 0.9772 - val_loss: 0.1885 - val_accuracy: 0.9715\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1631 - accuracy: 0.9808 - val_loss: 0.1747 - val_accuracy: 0.9754\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1536 - accuracy: 0.9834 - val_loss: 0.1716 - val_accuracy: 0.9762\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1448 - accuracy: 0.9861 - val_loss: 0.1759 - val_accuracy: 0.9742\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1375 - accuracy: 0.9877 - val_loss: 0.1738 - val_accuracy: 0.9747\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1312 - accuracy: 0.9897 - val_loss: 0.1594 - val_accuracy: 0.9787\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1259 - accuracy: 0.9907 - val_loss: 0.1568 - val_accuracy: 0.9800\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1210 - accuracy: 0.9921 - val_loss: 0.1525 - val_accuracy: 0.9804\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1163 - accuracy: 0.9934 - val_loss: 0.1527 - val_accuracy: 0.9795\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1125 - accuracy: 0.9943 - val_loss: 0.1499 - val_accuracy: 0.9798\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1090 - accuracy: 0.9950 - val_loss: 0.1521 - val_accuracy: 0.9802\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1055 - accuracy: 0.9961 - val_loss: 0.1445 - val_accuracy: 0.9815\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1024 - accuracy: 0.9970 - val_loss: 0.1443 - val_accuracy: 0.9808\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0996 - accuracy: 0.9973 - val_loss: 0.1425 - val_accuracy: 0.9822\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9979 - val_loss: 0.1414 - val_accuracy: 0.9811\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0949 - accuracy: 0.9982 - val_loss: 0.1424 - val_accuracy: 0.9813\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0926 - accuracy: 0.9986 - val_loss: 0.1390 - val_accuracy: 0.9814\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0905 - accuracy: 0.9987 - val_loss: 0.1370 - val_accuracy: 0.9820\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0888 - accuracy: 0.9989 - val_loss: 0.1356 - val_accuracy: 0.9817\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9992 - val_loss: 0.1341 - val_accuracy: 0.9818\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.9993 - val_loss: 0.1340 - val_accuracy: 0.9811\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0836 - accuracy: 0.9995 - val_loss: 0.1311 - val_accuracy: 0.9823\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0822 - accuracy: 0.9995 - val_loss: 0.1325 - val_accuracy: 0.9824\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0807 - accuracy: 0.9995 - val_loss: 0.1303 - val_accuracy: 0.9822\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0792 - accuracy: 0.9996 - val_loss: 0.1283 - val_accuracy: 0.9819\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0779 - accuracy: 0.9997 - val_loss: 0.1283 - val_accuracy: 0.9819\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.9997 - val_loss: 0.1296 - val_accuracy: 0.9811\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0753 - accuracy: 0.9998 - val_loss: 0.1258 - val_accuracy: 0.9816\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9998 - val_loss: 0.1253 - val_accuracy: 0.9823\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9998 - val_loss: 0.1256 - val_accuracy: 0.9825\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9999 - val_loss: 0.1221 - val_accuracy: 0.9821\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0707 - accuracy: 0.9998 - val_loss: 0.1221 - val_accuracy: 0.9815\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0697 - accuracy: 0.9999 - val_loss: 0.1217 - val_accuracy: 0.9818\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0685 - accuracy: 0.9999 - val_loss: 0.1214 - val_accuracy: 0.9818\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0675 - accuracy: 0.9999 - val_loss: 0.1197 - val_accuracy: 0.9821\n",
            "Regularization Factor 0.0001 - Test loss: 0.11968881636857986, Test accuracy: 0.9821000099182129\n",
            "\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.0001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.5039 - accuracy: 0.8868 - val_loss: 0.3202 - val_accuracy: 0.9325\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2877 - accuracy: 0.9453 - val_loss: 0.2562 - val_accuracy: 0.9533\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2369 - accuracy: 0.9602 - val_loss: 0.2231 - val_accuracy: 0.9628\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2068 - accuracy: 0.9685 - val_loss: 0.2039 - val_accuracy: 0.9674\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1874 - accuracy: 0.9740 - val_loss: 0.1987 - val_accuracy: 0.9684\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1720 - accuracy: 0.9786 - val_loss: 0.1814 - val_accuracy: 0.9740\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1606 - accuracy: 0.9816 - val_loss: 0.1829 - val_accuracy: 0.9727\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1512 - accuracy: 0.9847 - val_loss: 0.1714 - val_accuracy: 0.9760\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1427 - accuracy: 0.9867 - val_loss: 0.1675 - val_accuracy: 0.9763\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1360 - accuracy: 0.9886 - val_loss: 0.1613 - val_accuracy: 0.9788\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9901 - val_loss: 0.1600 - val_accuracy: 0.9785\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1245 - accuracy: 0.9915 - val_loss: 0.1566 - val_accuracy: 0.9797\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1197 - accuracy: 0.9923 - val_loss: 0.1531 - val_accuracy: 0.9797\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1155 - accuracy: 0.9936 - val_loss: 0.1521 - val_accuracy: 0.9801\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1113 - accuracy: 0.9948 - val_loss: 0.1551 - val_accuracy: 0.9787\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1082 - accuracy: 0.9954 - val_loss: 0.1507 - val_accuracy: 0.9804\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9962 - val_loss: 0.1487 - val_accuracy: 0.9798\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1018 - accuracy: 0.9968 - val_loss: 0.1431 - val_accuracy: 0.9805\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0989 - accuracy: 0.9976 - val_loss: 0.1436 - val_accuracy: 0.9814\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0964 - accuracy: 0.9979 - val_loss: 0.1407 - val_accuracy: 0.9815\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0943 - accuracy: 0.9983 - val_loss: 0.1415 - val_accuracy: 0.9815\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0920 - accuracy: 0.9988 - val_loss: 0.1376 - val_accuracy: 0.9814\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9990 - val_loss: 0.1414 - val_accuracy: 0.9793\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.9989 - val_loss: 0.1375 - val_accuracy: 0.9814\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0863 - accuracy: 0.9991 - val_loss: 0.1361 - val_accuracy: 0.9810\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0847 - accuracy: 0.9994 - val_loss: 0.1365 - val_accuracy: 0.9800\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0832 - accuracy: 0.9995 - val_loss: 0.1345 - val_accuracy: 0.9808\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0817 - accuracy: 0.9995 - val_loss: 0.1312 - val_accuracy: 0.9821\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0801 - accuracy: 0.9996 - val_loss: 0.1315 - val_accuracy: 0.9815\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0787 - accuracy: 0.9997 - val_loss: 0.1296 - val_accuracy: 0.9816\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0774 - accuracy: 0.9997 - val_loss: 0.1288 - val_accuracy: 0.9821\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0762 - accuracy: 0.9998 - val_loss: 0.1292 - val_accuracy: 0.9812\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0749 - accuracy: 0.9998 - val_loss: 0.1270 - val_accuracy: 0.9814\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0737 - accuracy: 0.9998 - val_loss: 0.1257 - val_accuracy: 0.9819\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9999 - val_loss: 0.1237 - val_accuracy: 0.9822\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9822\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0703 - accuracy: 0.9999 - val_loss: 0.1231 - val_accuracy: 0.9818\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - accuracy: 0.9999 - val_loss: 0.1214 - val_accuracy: 0.9820\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9822\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9999 - val_loss: 0.1197 - val_accuracy: 0.9823\n",
            "Regularization Factor 0.0001 - Test loss: 0.11970887333154678, Test accuracy: 0.9822999835014343\n",
            "\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.3250 - accuracy: 0.8891 - val_loss: 1.0656 - val_accuracy: 0.9355\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.9424 - val_loss: 0.8949 - val_accuracy: 0.9474\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8131 - accuracy: 0.9576 - val_loss: 0.7548 - val_accuracy: 0.9576\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6873 - accuracy: 0.9647 - val_loss: 0.6324 - val_accuracy: 0.9659\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5870 - accuracy: 0.9702 - val_loss: 0.5516 - val_accuracy: 0.9682\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5058 - accuracy: 0.9732 - val_loss: 0.4823 - val_accuracy: 0.9694\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4386 - accuracy: 0.9773 - val_loss: 0.4194 - val_accuracy: 0.9718\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3834 - accuracy: 0.9787 - val_loss: 0.3697 - val_accuracy: 0.9751\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3367 - accuracy: 0.9806 - val_loss: 0.3307 - val_accuracy: 0.9751\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2990 - accuracy: 0.9821 - val_loss: 0.2988 - val_accuracy: 0.9751\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2679 - accuracy: 0.9834 - val_loss: 0.2741 - val_accuracy: 0.9741\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2411 - accuracy: 0.9845 - val_loss: 0.2570 - val_accuracy: 0.9728\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2193 - accuracy: 0.9850 - val_loss: 0.2274 - val_accuracy: 0.9779\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2004 - accuracy: 0.9859 - val_loss: 0.2120 - val_accuracy: 0.9776\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1848 - accuracy: 0.9870 - val_loss: 0.1983 - val_accuracy: 0.9787\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1714 - accuracy: 0.9874 - val_loss: 0.1950 - val_accuracy: 0.9735\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1597 - accuracy: 0.9880 - val_loss: 0.1772 - val_accuracy: 0.9786\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1506 - accuracy: 0.9885 - val_loss: 0.1672 - val_accuracy: 0.9806\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1424 - accuracy: 0.9890 - val_loss: 0.1655 - val_accuracy: 0.9782\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1363 - accuracy: 0.9892 - val_loss: 0.1581 - val_accuracy: 0.9783\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1299 - accuracy: 0.9896 - val_loss: 0.1547 - val_accuracy: 0.9800\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1250 - accuracy: 0.9897 - val_loss: 0.1458 - val_accuracy: 0.9808\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1206 - accuracy: 0.9902 - val_loss: 0.1658 - val_accuracy: 0.9731\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1166 - accuracy: 0.9907 - val_loss: 0.1489 - val_accuracy: 0.9774\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9910 - val_loss: 0.1378 - val_accuracy: 0.9801\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1102 - accuracy: 0.9907 - val_loss: 0.1433 - val_accuracy: 0.9780\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1068 - accuracy: 0.9916 - val_loss: 0.1290 - val_accuracy: 0.9824\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1051 - accuracy: 0.9915 - val_loss: 0.1284 - val_accuracy: 0.9810\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9922 - val_loss: 0.1306 - val_accuracy: 0.9800\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1018 - accuracy: 0.9918 - val_loss: 0.1267 - val_accuracy: 0.9818\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1005 - accuracy: 0.9920 - val_loss: 0.1253 - val_accuracy: 0.9810\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0983 - accuracy: 0.9918 - val_loss: 0.1241 - val_accuracy: 0.9821\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0972 - accuracy: 0.9927 - val_loss: 0.1239 - val_accuracy: 0.9818\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0954 - accuracy: 0.9931 - val_loss: 0.1216 - val_accuracy: 0.9819\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0948 - accuracy: 0.9927 - val_loss: 0.1326 - val_accuracy: 0.9783\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0940 - accuracy: 0.9925 - val_loss: 0.1234 - val_accuracy: 0.9811\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0914 - accuracy: 0.9938 - val_loss: 0.1368 - val_accuracy: 0.9755\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0922 - accuracy: 0.9929 - val_loss: 0.1209 - val_accuracy: 0.9817\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9938 - val_loss: 0.1174 - val_accuracy: 0.9821\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0905 - accuracy: 0.9930 - val_loss: 0.1147 - val_accuracy: 0.9824\n",
            "Regularization Factor 0.001 - Test loss: 0.11472342163324356, Test accuracy: 0.9824000000953674\n",
            "\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.3323 - accuracy: 0.8868 - val_loss: 1.0743 - val_accuracy: 0.9350\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9830 - accuracy: 0.9421 - val_loss: 0.8850 - val_accuracy: 0.9527\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.8147 - accuracy: 0.9571 - val_loss: 0.7564 - val_accuracy: 0.9568\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6880 - accuracy: 0.9657 - val_loss: 0.6419 - val_accuracy: 0.9639\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5875 - accuracy: 0.9704 - val_loss: 0.5486 - val_accuracy: 0.9679\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5055 - accuracy: 0.9746 - val_loss: 0.4868 - val_accuracy: 0.9687\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4388 - accuracy: 0.9776 - val_loss: 0.4260 - val_accuracy: 0.9707\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3833 - accuracy: 0.9793 - val_loss: 0.3722 - val_accuracy: 0.9737\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3375 - accuracy: 0.9809 - val_loss: 0.3364 - val_accuracy: 0.9734\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2991 - accuracy: 0.9826 - val_loss: 0.2930 - val_accuracy: 0.9784\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.9837 - val_loss: 0.2739 - val_accuracy: 0.9753\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2410 - accuracy: 0.9843 - val_loss: 0.2477 - val_accuracy: 0.9779\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2189 - accuracy: 0.9859 - val_loss: 0.2266 - val_accuracy: 0.9793\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1999 - accuracy: 0.9862 - val_loss: 0.2103 - val_accuracy: 0.9791\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1850 - accuracy: 0.9871 - val_loss: 0.1978 - val_accuracy: 0.9776\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1708 - accuracy: 0.9879 - val_loss: 0.1922 - val_accuracy: 0.9776\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1609 - accuracy: 0.9878 - val_loss: 0.1730 - val_accuracy: 0.9798\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1502 - accuracy: 0.9885 - val_loss: 0.1745 - val_accuracy: 0.9782\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1422 - accuracy: 0.9887 - val_loss: 0.1636 - val_accuracy: 0.9783\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1356 - accuracy: 0.9894 - val_loss: 0.1645 - val_accuracy: 0.9772\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1293 - accuracy: 0.9898 - val_loss: 0.1472 - val_accuracy: 0.9809\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1245 - accuracy: 0.9901 - val_loss: 0.1434 - val_accuracy: 0.9804\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1201 - accuracy: 0.9907 - val_loss: 0.1397 - val_accuracy: 0.9818\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9907 - val_loss: 0.1432 - val_accuracy: 0.9804\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1134 - accuracy: 0.9909 - val_loss: 0.1344 - val_accuracy: 0.9809\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9915 - val_loss: 0.1334 - val_accuracy: 0.9806\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9915 - val_loss: 0.1266 - val_accuracy: 0.9821\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1052 - accuracy: 0.9913 - val_loss: 0.1296 - val_accuracy: 0.9804\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9918 - val_loss: 0.1334 - val_accuracy: 0.9786\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1007 - accuracy: 0.9923 - val_loss: 0.1314 - val_accuracy: 0.9787\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0995 - accuracy: 0.9924 - val_loss: 0.1266 - val_accuracy: 0.9798\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9926 - val_loss: 0.1273 - val_accuracy: 0.9810\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9926 - val_loss: 0.1217 - val_accuracy: 0.9808\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9923 - val_loss: 0.1200 - val_accuracy: 0.9814\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9927 - val_loss: 0.1190 - val_accuracy: 0.9813\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9932 - val_loss: 0.1202 - val_accuracy: 0.9807\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0922 - accuracy: 0.9931 - val_loss: 0.1179 - val_accuracy: 0.9815\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0917 - accuracy: 0.9935 - val_loss: 0.1184 - val_accuracy: 0.9805\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9930 - val_loss: 0.1199 - val_accuracy: 0.9806\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0896 - accuracy: 0.9935 - val_loss: 0.1489 - val_accuracy: 0.9716\n",
            "Regularization Factor 0.001 - Test loss: 0.14890700578689575, Test accuracy: 0.9715999960899353\n",
            "\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.001\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.3241 - accuracy: 0.8888 - val_loss: 1.0689 - val_accuracy: 0.9337\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9806 - accuracy: 0.9424 - val_loss: 0.8903 - val_accuracy: 0.9472\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8134 - accuracy: 0.9571 - val_loss: 0.7444 - val_accuracy: 0.9602\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6880 - accuracy: 0.9648 - val_loss: 0.6356 - val_accuracy: 0.9654\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5883 - accuracy: 0.9697 - val_loss: 0.5544 - val_accuracy: 0.9685\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5063 - accuracy: 0.9740 - val_loss: 0.4876 - val_accuracy: 0.9684\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4394 - accuracy: 0.9762 - val_loss: 0.4185 - val_accuracy: 0.9734\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3834 - accuracy: 0.9787 - val_loss: 0.3752 - val_accuracy: 0.9730\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3379 - accuracy: 0.9809 - val_loss: 0.3328 - val_accuracy: 0.9743\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.9817 - val_loss: 0.2962 - val_accuracy: 0.9760\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2679 - accuracy: 0.9836 - val_loss: 0.2711 - val_accuracy: 0.9760\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2418 - accuracy: 0.9844 - val_loss: 0.2459 - val_accuracy: 0.9780\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2187 - accuracy: 0.9855 - val_loss: 0.2255 - val_accuracy: 0.9790\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2004 - accuracy: 0.9859 - val_loss: 0.2117 - val_accuracy: 0.9783\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1851 - accuracy: 0.9863 - val_loss: 0.1975 - val_accuracy: 0.9778\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1707 - accuracy: 0.9880 - val_loss: 0.1850 - val_accuracy: 0.9791\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1602 - accuracy: 0.9876 - val_loss: 0.1803 - val_accuracy: 0.9766\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1504 - accuracy: 0.9885 - val_loss: 0.1712 - val_accuracy: 0.9790\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1421 - accuracy: 0.9894 - val_loss: 0.1617 - val_accuracy: 0.9786\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1352 - accuracy: 0.9898 - val_loss: 0.1546 - val_accuracy: 0.9797\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1291 - accuracy: 0.9901 - val_loss: 0.1518 - val_accuracy: 0.9800\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1244 - accuracy: 0.9903 - val_loss: 0.1532 - val_accuracy: 0.9777\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1199 - accuracy: 0.9904 - val_loss: 0.1423 - val_accuracy: 0.9808\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9913 - val_loss: 0.1540 - val_accuracy: 0.9756\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1129 - accuracy: 0.9909 - val_loss: 0.1428 - val_accuracy: 0.9787\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1098 - accuracy: 0.9917 - val_loss: 0.1348 - val_accuracy: 0.9808\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9912 - val_loss: 0.1316 - val_accuracy: 0.9808\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1051 - accuracy: 0.9916 - val_loss: 0.1361 - val_accuracy: 0.9790\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9919 - val_loss: 0.1357 - val_accuracy: 0.9805\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9922 - val_loss: 0.1338 - val_accuracy: 0.9786\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1006 - accuracy: 0.9915 - val_loss: 0.1287 - val_accuracy: 0.9797\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9925 - val_loss: 0.1260 - val_accuracy: 0.9807\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0965 - accuracy: 0.9928 - val_loss: 0.1212 - val_accuracy: 0.9816\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9928 - val_loss: 0.1231 - val_accuracy: 0.9817\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0945 - accuracy: 0.9926 - val_loss: 0.1224 - val_accuracy: 0.9816\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9930 - val_loss: 0.1188 - val_accuracy: 0.9810\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0918 - accuracy: 0.9935 - val_loss: 0.1238 - val_accuracy: 0.9794\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0918 - accuracy: 0.9934 - val_loss: 0.1253 - val_accuracy: 0.9802\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0911 - accuracy: 0.9934 - val_loss: 0.1167 - val_accuracy: 0.9810\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0896 - accuracy: 0.9939 - val_loss: 0.1163 - val_accuracy: 0.9817\n",
            "Regularization Factor 0.001 - Test loss: 0.1163473129272461, Test accuracy: 0.9817000031471252\n",
            "\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.01\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 5.0715 - accuracy: 0.8821 - val_loss: 2.0276 - val_accuracy: 0.9155\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.1835 - accuracy: 0.9223 - val_loss: 0.7013 - val_accuracy: 0.9305\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.9325 - val_loss: 0.4647 - val_accuracy: 0.9403\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4525 - accuracy: 0.9379 - val_loss: 0.4217 - val_accuracy: 0.9424\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4174 - accuracy: 0.9425 - val_loss: 0.3948 - val_accuracy: 0.9477\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3979 - accuracy: 0.9458 - val_loss: 0.3778 - val_accuracy: 0.9493\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3845 - accuracy: 0.9471 - val_loss: 0.3889 - val_accuracy: 0.9423\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3740 - accuracy: 0.9490 - val_loss: 0.3591 - val_accuracy: 0.9503\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3647 - accuracy: 0.9513 - val_loss: 0.3516 - val_accuracy: 0.9512\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3584 - accuracy: 0.9516 - val_loss: 0.3899 - val_accuracy: 0.9428\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3504 - accuracy: 0.9536 - val_loss: 0.3782 - val_accuracy: 0.9397\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3462 - accuracy: 0.9536 - val_loss: 0.3233 - val_accuracy: 0.9606\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3393 - accuracy: 0.9546 - val_loss: 0.3275 - val_accuracy: 0.9593\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3329 - accuracy: 0.9568 - val_loss: 0.3296 - val_accuracy: 0.9519\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3309 - accuracy: 0.9560 - val_loss: 0.3288 - val_accuracy: 0.9559\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3276 - accuracy: 0.9573 - val_loss: 0.3211 - val_accuracy: 0.9579\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3224 - accuracy: 0.9578 - val_loss: 0.3121 - val_accuracy: 0.9612\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3197 - accuracy: 0.9583 - val_loss: 0.3205 - val_accuracy: 0.9543\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3174 - accuracy: 0.9584 - val_loss: 0.3081 - val_accuracy: 0.9569\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3168 - accuracy: 0.9580 - val_loss: 0.3070 - val_accuracy: 0.9617\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3115 - accuracy: 0.9589 - val_loss: 0.3131 - val_accuracy: 0.9565\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3097 - accuracy: 0.9592 - val_loss: 0.3014 - val_accuracy: 0.9611\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.9595 - val_loss: 0.2980 - val_accuracy: 0.9609\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3075 - accuracy: 0.9590 - val_loss: 0.3067 - val_accuracy: 0.9565\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3042 - accuracy: 0.9594 - val_loss: 0.2818 - val_accuracy: 0.9661\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3065 - accuracy: 0.9589 - val_loss: 0.3873 - val_accuracy: 0.9235\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3004 - accuracy: 0.9605 - val_loss: 0.3013 - val_accuracy: 0.9595\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2967 - accuracy: 0.9602 - val_loss: 0.7281 - val_accuracy: 0.8312\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3016 - accuracy: 0.9584 - val_loss: 0.2882 - val_accuracy: 0.9648\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2956 - accuracy: 0.9613 - val_loss: 0.2982 - val_accuracy: 0.9583\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2940 - accuracy: 0.9608 - val_loss: 0.2781 - val_accuracy: 0.9650\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2964 - accuracy: 0.9598 - val_loss: 0.3343 - val_accuracy: 0.9443\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.9617 - val_loss: 0.2951 - val_accuracy: 0.9610\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3099 - accuracy: 0.9566 - val_loss: 0.2802 - val_accuracy: 0.9646\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2927 - accuracy: 0.9609 - val_loss: 0.2814 - val_accuracy: 0.9652\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2901 - accuracy: 0.9610 - val_loss: 0.2923 - val_accuracy: 0.9602\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2920 - accuracy: 0.9604 - val_loss: 0.3991 - val_accuracy: 0.9223\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3077 - accuracy: 0.9569 - val_loss: 0.2799 - val_accuracy: 0.9649\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2954 - accuracy: 0.9604 - val_loss: 0.2810 - val_accuracy: 0.9629\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2907 - accuracy: 0.9607 - val_loss: 0.3022 - val_accuracy: 0.9561\n",
            "Regularization Factor 0.01 - Test loss: 0.30216214060783386, Test accuracy: 0.9560999870300293\n",
            "\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.01\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 5.0769 - accuracy: 0.8774 - val_loss: 2.0290 - val_accuracy: 0.9096\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.1854 - accuracy: 0.9214 - val_loss: 0.6978 - val_accuracy: 0.9308\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5713 - accuracy: 0.9316 - val_loss: 0.4707 - val_accuracy: 0.9377\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4536 - accuracy: 0.9374 - val_loss: 0.4131 - val_accuracy: 0.9443\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4161 - accuracy: 0.9419 - val_loss: 0.4062 - val_accuracy: 0.9417\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3996 - accuracy: 0.9451 - val_loss: 0.3719 - val_accuracy: 0.9508\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3846 - accuracy: 0.9473 - val_loss: 0.3733 - val_accuracy: 0.9460\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3751 - accuracy: 0.9497 - val_loss: 0.3840 - val_accuracy: 0.9430\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3657 - accuracy: 0.9510 - val_loss: 0.3604 - val_accuracy: 0.9482\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3592 - accuracy: 0.9516 - val_loss: 0.3553 - val_accuracy: 0.9525\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3514 - accuracy: 0.9524 - val_loss: 0.3346 - val_accuracy: 0.9552\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3443 - accuracy: 0.9540 - val_loss: 0.3240 - val_accuracy: 0.9597\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3382 - accuracy: 0.9556 - val_loss: 0.3930 - val_accuracy: 0.9297\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3345 - accuracy: 0.9556 - val_loss: 0.3319 - val_accuracy: 0.9545\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3305 - accuracy: 0.9559 - val_loss: 0.3256 - val_accuracy: 0.9583\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3292 - accuracy: 0.9557 - val_loss: 0.3414 - val_accuracy: 0.9518\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3223 - accuracy: 0.9585 - val_loss: 0.2979 - val_accuracy: 0.9634\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3179 - accuracy: 0.9586 - val_loss: 0.3041 - val_accuracy: 0.9620\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3196 - accuracy: 0.9568 - val_loss: 0.3246 - val_accuracy: 0.9546\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3127 - accuracy: 0.9593 - val_loss: 0.3013 - val_accuracy: 0.9605\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3215 - accuracy: 0.9568 - val_loss: 0.3158 - val_accuracy: 0.9537\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3108 - accuracy: 0.9587 - val_loss: 0.2993 - val_accuracy: 0.9637\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3090 - accuracy: 0.9590 - val_loss: 0.2947 - val_accuracy: 0.9628\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3060 - accuracy: 0.9596 - val_loss: 0.2890 - val_accuracy: 0.9635\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3035 - accuracy: 0.9604 - val_loss: 0.3259 - val_accuracy: 0.9525\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3035 - accuracy: 0.9599 - val_loss: 0.2894 - val_accuracy: 0.9635\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3005 - accuracy: 0.9604 - val_loss: 0.2899 - val_accuracy: 0.9617\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2968 - accuracy: 0.9611 - val_loss: 0.2933 - val_accuracy: 0.9626\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3007 - accuracy: 0.9597 - val_loss: 0.2993 - val_accuracy: 0.9579\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3000 - accuracy: 0.9586 - val_loss: 0.3347 - val_accuracy: 0.9520\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2943 - accuracy: 0.9612 - val_loss: 0.2953 - val_accuracy: 0.9600\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2964 - accuracy: 0.9599 - val_loss: 0.3206 - val_accuracy: 0.9472\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2944 - accuracy: 0.9605 - val_loss: 0.3007 - val_accuracy: 0.9547\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3069 - accuracy: 0.9573 - val_loss: 0.2924 - val_accuracy: 0.9609\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2965 - accuracy: 0.9593 - val_loss: 0.2929 - val_accuracy: 0.9602\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.9575 - val_loss: 0.7537 - val_accuracy: 0.7865\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3038 - accuracy: 0.9596 - val_loss: 0.3021 - val_accuracy: 0.9529\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2992 - accuracy: 0.9585 - val_loss: 0.2778 - val_accuracy: 0.9643\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3083 - accuracy: 0.9570 - val_loss: 0.2971 - val_accuracy: 0.9576\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2934 - accuracy: 0.9598 - val_loss: 0.2773 - val_accuracy: 0.9659\n",
            "Regularization Factor 0.01 - Test loss: 0.2773204743862152, Test accuracy: 0.9659000039100647\n",
            "\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training model with regularization factor: 0.01\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 5.0679 - accuracy: 0.8786 - val_loss: 2.0006 - val_accuracy: 0.9263\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.1830 - accuracy: 0.9216 - val_loss: 0.6954 - val_accuracy: 0.9343\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5740 - accuracy: 0.9297 - val_loss: 0.4700 - val_accuracy: 0.9370\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4548 - accuracy: 0.9371 - val_loss: 0.4248 - val_accuracy: 0.9421\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4212 - accuracy: 0.9406 - val_loss: 0.4435 - val_accuracy: 0.9250\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4011 - accuracy: 0.9434 - val_loss: 0.3899 - val_accuracy: 0.9453\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3869 - accuracy: 0.9478 - val_loss: 0.3791 - val_accuracy: 0.9472\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3748 - accuracy: 0.9489 - val_loss: 0.3551 - val_accuracy: 0.9536\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3681 - accuracy: 0.9490 - val_loss: 0.3437 - val_accuracy: 0.9561\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3592 - accuracy: 0.9513 - val_loss: 0.3491 - val_accuracy: 0.9550\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.9525 - val_loss: 0.3834 - val_accuracy: 0.9373\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3464 - accuracy: 0.9538 - val_loss: 0.3276 - val_accuracy: 0.9572\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.9549 - val_loss: 0.3180 - val_accuracy: 0.9616\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3335 - accuracy: 0.9562 - val_loss: 0.3177 - val_accuracy: 0.9593\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3300 - accuracy: 0.9567 - val_loss: 0.3130 - val_accuracy: 0.9617\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3274 - accuracy: 0.9565 - val_loss: 0.3145 - val_accuracy: 0.9588\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3207 - accuracy: 0.9583 - val_loss: 0.3255 - val_accuracy: 0.9546\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3201 - accuracy: 0.9572 - val_loss: 0.3102 - val_accuracy: 0.9616\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3222 - accuracy: 0.9575 - val_loss: 0.2979 - val_accuracy: 0.9633\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3139 - accuracy: 0.9587 - val_loss: 0.3546 - val_accuracy: 0.9404\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3116 - accuracy: 0.9589 - val_loss: 0.3162 - val_accuracy: 0.9562\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3104 - accuracy: 0.9592 - val_loss: 0.3892 - val_accuracy: 0.9311\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3249 - accuracy: 0.9560 - val_loss: 0.3123 - val_accuracy: 0.9619\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3119 - accuracy: 0.9591 - val_loss: 0.2979 - val_accuracy: 0.9637\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3056 - accuracy: 0.9597 - val_loss: 0.2968 - val_accuracy: 0.9609\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3032 - accuracy: 0.9594 - val_loss: 0.2977 - val_accuracy: 0.9584\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3023 - accuracy: 0.9594 - val_loss: 0.2959 - val_accuracy: 0.9595\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2976 - accuracy: 0.9606 - val_loss: 0.2774 - val_accuracy: 0.9659\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2978 - accuracy: 0.9600 - val_loss: 0.3180 - val_accuracy: 0.9517\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2995 - accuracy: 0.9589 - val_loss: 0.2847 - val_accuracy: 0.9642\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2990 - accuracy: 0.9594 - val_loss: 0.2830 - val_accuracy: 0.9646\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2942 - accuracy: 0.9607 - val_loss: 0.3136 - val_accuracy: 0.9520\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3110 - accuracy: 0.9557 - val_loss: 0.3557 - val_accuracy: 0.9533\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3154 - accuracy: 0.9570 - val_loss: 0.2895 - val_accuracy: 0.9630\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2933 - accuracy: 0.9616 - val_loss: 0.2737 - val_accuracy: 0.9667\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2906 - accuracy: 0.9614 - val_loss: 0.2968 - val_accuracy: 0.9572\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2984 - accuracy: 0.9593 - val_loss: 0.2775 - val_accuracy: 0.9664\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.9596 - val_loss: 0.2980 - val_accuracy: 0.9595\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2991 - accuracy: 0.9591 - val_loss: 0.3057 - val_accuracy: 0.9545\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2875 - accuracy: 0.9618 - val_loss: 0.2715 - val_accuracy: 0.9658\n",
            "Regularization Factor 0.01 - Test loss: 0.27152886986732483, Test accuracy: 0.9657999873161316\n",
            "\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545810 (2.08 MB)\n",
            "Trainable params: 545810 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# fit_info.history[val_accuracy]\n",
        "# mean_accuracies = np.mean(fit_info.history['val_accuracy'])\n",
        "# std_accuracies = np.std(fit_info.history['val_accuracy'])\n",
        "\n",
        "display(val_acc_mean_tot)\n",
        "display(std_acc_tot)\n",
        "\n",
        "# Plot\n",
        "plt.errorbar(regularization_factors, val_acc_mean_tot, yerr=std_acc_tot, fmt='o-', label='Validation Accuracy')\n",
        "plt.xscale('log')  # Use a logarithmic scale for the x-axis\n",
        "plt.xlabel('Regularization Factor')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Validation Accuracy vs. Regularization Factor')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "EdAVdVlGwtDb",
        "outputId": "e9ee101b-ea2e-4b41-8233-fb3966a48ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.9774600004156431,\n",
              " 0.9771574998895327,\n",
              " 0.9774283359448115,\n",
              " 0.9755225002765655,\n",
              " 0.9507433334986369]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.00919823501349758,\n",
              " 0.008920040266837757,\n",
              " 0.00892227760285728,\n",
              " 0.009344849320801344,\n",
              " 0.022019954410692343]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3\n"
      ],
      "metadata": {
        "id": "zOhsW1sYwhDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convolutional layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # Flattening the 2D arrays for dense layers\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "val_acc_conv.append((fit_info.history['val_accuracy']))\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHaoRmZXLJ2",
        "outputId": "2c0e194e-bf9b-470c-835c-d430231319b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3697 - accuracy: 0.8906 - val_loss: 0.0881 - val_accuracy: 0.9717\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0827 - accuracy: 0.9747 - val_loss: 0.0822 - val_accuracy: 0.9733\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0558 - accuracy: 0.9827 - val_loss: 0.0490 - val_accuracy: 0.9832\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.0409 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0453 - val_accuracy: 0.9853\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0327 - val_accuracy: 0.9881\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0367 - val_accuracy: 0.9878\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0425 - val_accuracy: 0.9862\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0310 - val_accuracy: 0.9903\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0317 - val_accuracy: 0.9905\n",
            "Test loss: 0.031736161559820175, Test accuracy 0.9904999732971191\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPooli  (None, 13, 13, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 11, 11, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPooli  (None, 5, 5, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 800)               0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 500)               400500    \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 563378 (2.15 MB)\n",
            "Trainable params: 563378 (2.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(conv_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RUBDiYCGSVxm",
        "outputId": "82dad10d-b0f3-4ef5-9106-b12532aef653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9847100039323171"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Left-overs"
      ],
      "metadata": {
        "id": "e3T0pk1vMZ7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "input_img = Input(shape=(input_dim,))\n",
        "encoder_layer = model.layers[0]\n",
        "encoder = Model(input_img, encoder_layer(input_img))\n",
        "\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "s6Aze_R-EuVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim"
      ],
      "metadata": {
        "id": "Pbw3Hm_aHEKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_idx"
      ],
      "metadata": {
        "id": "Slz82yfnI9Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_images = 10\n",
        "np.random.seed(42)\n",
        "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
        "\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = model.predict(x_test)\n",
        "\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "for i, image_idx in enumerate(random_test_images):\n",
        "    # plot original image\n",
        "    ax = plt.subplot(3, num_images, i + 1)\n",
        "    print(x_test[image_idx].size)\n",
        "    plt.imshow(x_test[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # plot encoded image\n",
        "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
        "    print(encoded_imgs[image_idx].size)\n",
        "    plt.imshow(encoded_imgs[image_idx].reshape(28,28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # plot reconstructed image\n",
        "    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
        "    print(decoded_imgs[image_idx].size)\n",
        "    plt.imshow(decoded_imgs[image_idx].reshape(10,10))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TUmxBjQbEB2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rvo4IMNofuEt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e3T0pk1vMZ7X"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}